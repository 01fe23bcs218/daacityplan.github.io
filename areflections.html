<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Course Learning Reflections</title>
    <link rel="stylesheet" href="areflections.css"> <!-- Link to external CSS -->
</head>
<body>
    <header>
        <div class="logo">Anirudh's Reflections</div>
        <nav>
            <a href="index.html">Home</a>
            <a href="reflections.html" class="active">Reflections</a>
        </nav>
    </header>

    <main>
        <section class="content">
            <h1>Course Learning Reflections</h1>
            
            <!-- Section 1 -->
            <div class="section">
                <h2>1. Problems Observed in Nature and Computational Approaches</h2>
                <ul>
                    <li><strong>Iterative Problems:</strong> Iteration is a repeated process, such as traversing a list or performing calculations with loops (e.g., matrix multiplication).</li>
                    <li><strong>Recursive Problems:</strong> Recursion is when a function calls itself to solve problems like the Fibonacci sequence or tree traversal.</li>
                    <li><strong>Backtracking Problems:</strong> Backtracking involves trying different paths and returning to the last decision when a dead end is encountered (e.g., solving Sudoku or N-Queens).</li>
                </ul>
                <p><strong>Reflection:</strong> Nature exhibits iterative phenomena (e.g., daily cycles), recursive patterns (e.g., fractals), and complex decisions (e.g., ant colony optimization), mimicked in computational problems.</p>
            </div>

            <!-- Section 2 -->
            <div class="section">
                <h2>2. Space and Time Efficiency</h2>
                <p><strong>Definitions:</strong></p>
                <ul>
                    <li><strong>Time efficiency:</strong> Measures how quickly an algorithm runs, usually based on input size.</li>
                    <li><strong>Space efficiency:</strong> Measures how much memory an algorithm requires.</li>
                </ul>
                <p><strong>Importance:</strong></p>
                <ul>
                    <li>Performance Analysis</li>
                    <li>Algorithm Comparison</li>
                    <li>Optimization and Improvement</li>
                    <li>Resource Management</li>
                    <li>Scalability</li>
                </ul>
                <p><strong>Reflection:</strong> Balancing time and space efficiency is pivotal when optimizing algorithms, such as when deciding between recursion and iteration.</p>
            </div>

            <!-- Section 3 -->
            <div class="section">
                <h2>3. Hashing and Design Principles</h2>
                <ul>
                    <li><strong>Direct Address Tables:</strong> The simplest form of key-value storage.</li>
                    <li><strong>Hash Functions:</strong> The importance of good hash functions in ensuring uniform distribution.</li>
                    <li><strong>Collision Resolution:</strong> Techniques like chaining and open addressing.</li>
                </ul>
                <p><strong>Reflection:</strong> The efficiency of hashing directly impacts applications like databases and caches, where fast lookups are critical.</p>
            </div>

            <!-- Section 4 -->
            <div class="section">
                <h2>4. Hierarchical Data and Tree Data Structures</h2>
                <ul>
                    <li><strong>Binary Trees and BST:</strong> Simple hierarchical data organization for efficient searching.</li>
                    <li><strong>AVL and 2-3 Trees:</strong> Balancing trees to maintain efficiency in operations.</li>
                    <li><strong>Tries and Heaps:</strong> Specialized trees for string storage and priority-based operations.</li>
                </ul>
                <p><strong>Reflection:</strong> Tree data structures allow hierarchical organization, balancing, and fast access, essential in applications like file systems and search engines.</p>
            </div>

            <!-- Section 5 -->
            <div class="section">
                <h2>5. Trees vs. Graphs</h2>
                <ul>
                    <li><strong>Structural Differences:</strong> Trees are hierarchical, while graphs are network-based.</li>
                    <li><strong>Traversal Techniques:</strong> DFS and BFS compared between trees and graphs.</li>
                </ul>
                <p><strong>Applications:</strong></p>
                <ul>
                    <li><strong>Trees:</strong> Parsing expressions, representing hierarchies.</li>
                    <li><strong>Graphs:</strong> Social networks, transportation systems.</li>
                </ul>
                <p><strong>Reflection:</strong> Understanding both structures helps in solving diverse problems, from organizational charts to complex network systems.</p>
            </div>

            <!-- Section 6 -->
            <div class="section">
                <h2>6. Sorting and Searching Algorithms</h2>
                <ul>
                    <li><strong>Sorting Techniques:</strong> Comparing merge sort, quick sort, and heap sort.</li>
                    <li><strong>Search Algorithms:</strong> Linear vs. binary search and their use cases.</li>
                </ul>
                <p><strong>Real-World Connections:</strong> Applications in e-commerce, databases, and file systems.</p>
                <p><strong>Reflection:</strong> Sorting and searching help optimize data handling, storing, and accessing, improving the efficiency of systems handling large data.</p>
            </div>

            <!-- Section 8 -->
            <div class="section">
                <h2>8. Graph Algorithms: Spanning Trees and Shortest Paths</h2>
                <ul>
                    <li><strong>Spanning Trees:</strong> Applications in network design, such as minimal wiring.</li>
                    <li><strong>Shortest Paths:</strong> Importance in GPS navigation and network routing.</li>
                </ul>
                <p><strong>Reflection:</strong> Graph algorithms help solve real-world problems like infrastructure design and data flow optimization.</p>
            </div>

            <!-- Section 9 -->
            <div class="section">
                <h2>9. Algorithm Design Techniques</h2>
                <ul>
                    <li><strong>Divide and Conquer:</strong> Efficient problem-solving through decomposition (e.g., merge sort).</li>
                    <li><strong>Dynamic Programming:</strong> Optimizing overlapping subproblems (e.g., Knapsack problem).</li>
                    <li><strong>Greedy Algorithms:</strong> Immediate optimal decisions (e.g., Kruskal's algorithm).</li>
                </ul>
                <p><strong>Reflection:</strong> Each design technique offers a unique approach to problem-solving, applicable in diverse domains from optimization to game theory.</p>
            </div>

            <!-- Questions Section -->
            <section class="questions">
                <h2>Questions to Think On:</h2>

                <h3>1. Determining the Most Efficient Approach for Complex Problems</h3>
                <p>To solve a complex problem efficiently, itâ€™s important to first understand its requirements and constraints. I learned to categorize problems based on whether they suit iterative, recursive, or backtracking methods. For example, iterative methods are great for tasks like array traversal, while recursion is better for tree traversals or problems like N-Queens.</p>
                <p>Time and space complexities, introduced in Chapter 1, are crucial in choosing the right approach. For example, merge sort offers stable \(O(n \log n)\) performance but uses more memory, while quicksort is more space-efficient but can degrade to \(O(n^2)\) in the worst case.</p>
                <p>Choosing the right data structure also plays a key role. For quick lookups, hash tables are ideal, but handling collisions efficiently through techniques like chaining or open addressing is necessary to maintain performance.</p>

                <h3>2. Trade-Offs in Approaches</h3>
                <p><strong>Scenario:</strong> Choosing between DFS and BFS for graph traversal.</p>
                <p><strong>DFS:</strong> Better for exploring depth; less memory-intensive.</p>
                <p><strong>BFS:</strong> Finds shortest paths in unweighted graphs but can be memory-intensive.</p>
                <p><strong>Reflection:</strong> Choosing an approach depends on the specific requirements, such as memory constraints or traversal goals.</p>
            </section>
        </section>
    </main>
</body>
</html>
